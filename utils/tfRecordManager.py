'''
Created on 2018年12月14日

@author: zhangyanqing1
'''
import tensorflow as tf
tf.logging.set_verbosity(tf.logging.INFO)
logger = tf.logging
flags = tf.flags

FLAGS = flags.FLAGS


class TFRecordConvertor:
    def __init__(self, featureNames, featureTypes, featureDims=[]):
        self.featureNames = featureNames
        self.featureTypes = featureTypes
        self.featureDims = featureDims
        self.feature = dict()

        for name, valueType, dim in zip(self.featureNames, self.featureTypes, self.featureDims):
            self.feature[name] = self._featureToTensor(valueType, dim)

        self._toFeatureFunc = {
            tf.int64: self._int64ToFeature,
            tf.float32: self._floatToFeature,
            tf.string: self._bytesToFeature
        }

    def _sparseToDense(self, parse):
        return tf.sparse_to_dense(parse.indices, parse.dense_shape, parse.values, 0)

    def _int64ToFeature(self, value):
        return tf.train.Feature(int64_list=tf.train.Int64List(value=value))

    def _bytesToFeature(self, value):
        return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))

    def _floatToFeature(self, value):
        return tf.train.Feature(float_list=tf.train.FloatList(value=value))

    def _valueToFeature(self, value, valueType):
        return self._toFeatureFunc[valueType](value)

    def _featureToTensor(self, valueType, dim=0):
        if dim != 0:
            return tf.FixedLenFeature([dim], valueType)
        else:
            return tf.VarLenFeature(valueType)

    def dataToExample(self, flds):
        '''
        flds: [[1,2,3],[b'music']]
        '''
        if len(flds) != len(self.featureNames):
            raise Exception("data length unequale to feature length")
        feature = dict()
        for data, name, valueType in zip(flds, self.featureNames, self.featureTypes):
            feature[name] = self._valueToFeature(data, valueType)
        example = tf.train.Example(features=tf.train.Features(feature=feature))
        return example

    def bytesToExample(self, exampleString):
        '''
        exampleString from TFRecord file or generated by example.SerializeToString()
        '''
        return tf.train.Example().FromString(exampleString)

    def headTFRecord(self, filename, headNum):
        TFRecordIterator = tf.python_io.tf_record_iterator(filename)
        for _ in range(headNum):
            tfString = next(TFRecordIterator)
            tf.logging.info(tf.train.Example().FromString(tfString))
        TFRecordIterator.close()

    def bytesToTensor(self, exampleString):
        '''
        exampleString from TFRecord file or generated by example.SerializeToString()
        '''
        return tf.parse_single_example(exampleString, features=self.feature)


class TFRecordWriter:
    def _lineToData(self, line):
        '''
        return: [[1,2,3],[b'music']]
        according to format defined in self.tfRecordConvertor
        '''
        raise NotImplementedError

    def _getConvertor(self):
        raise NotImplementedError

    def __init__(self, sourceFilePattern, tfRecordFilePrefix, fileLimit=0):
        self.tfRecordConvertor = self._getConvertor()
        self.sourceFilePattern = sourceFilePattern
        self.tfRecordFilePrefix = tfRecordFilePrefix
        self.fileLimit = fileLimit

    def writeTFRecord(self):
        source_files = tf.train.match_filenames_once(self.sourceFilePattern)
        source_data = tf.data.TextLineDataset(
            source_files).repeat(1).shuffle(1)
        source_iterator = source_data.make_initializable_iterator()
        line_tensor = source_iterator.get_next()

        init = (tf.global_variables_initializer(),
                tf.local_variables_initializer())
        with tf.Session() as sess:
            sess.run(init)
            sess.run(source_iterator.initializer)

            if self.fileLimit == 0:
                writer = tf.python_io.TFRecordWriter(self.tfRecordFilePrefix)
                logger.info("Generating TFRecordFile %s.tf" %
                            self.tfRecordFilePrefix)
                while True:
                    try:
                        line = sess.run(line_tensor).decode()
                        logger.info(line)
                        data = self._lineToData(line)
                        example = self.tfRecordConvertor.dataToExample(data)
                        writer.write(example.SerializeToString())
                    except tf.errors.OutOfRangeError:
                        writer.close()
                        break
            else:
                fileIndex = 0
                while True:
                    try:
                        writer = tf.python_io.TFRecordWriter('%s_%d.tf' %
                                                             (self.tfRecordFilePrefix, fileIndex))
                        logger.info("Generating TFRecordFile %s_%d.tf" %
                                    (self.tfRecordFilePrefix, fileIndex))
                        for _ in range(self.fileLimit):
                            line = sess.run(line_tensor).decode()
                            data = self._lineToData(line)
                            example = self.tfRecordConvertor.dataToExample(
                                data)
                            writer.write(example.SerializeToString())
                        writer.close()
                        fileIndex += 1
                    except tf.errors.OutOfRangeError:
                        writer.close()
                        logger.info("end of data")
                        break


class TFRecordReader:

    def __init__(self,
                 tfRecordFilePattern,
                 tfRecordConvertor=None,
                 fileShuffle=False,
                 fileBufferSize=None,
                 fileParallelReads=1,
                 dataBufferSize=1,
                 dataRepeat=1,
                 batchSize=None):
        '''
        fileBufferSize: buffer size of file read buffer, bytes
        '''
        self.tfRecordConvertor = tfRecordConvertor if tfRecordConvertor else self._getConvertor()
        self.tfRecordFilePattern = tfRecordFilePattern
        self.fileShuffle = fileShuffle
        self.dataBufferSize = dataBufferSize
        self.fileParallelReads = fileParallelReads
        self.dataRepeat = dataRepeat
        self.fileBufferSize = fileBufferSize
        self.batchSize = batchSize

    def _data_mapper(self, features):
        return features

    def _getConvertor(self):
        raise NotImplementedError

    def read(self):
        tf_files = tf.data.TFRecordDataset.list_files(
            self.tfRecordFilePattern, shuffle=self.fileShuffle)
        tf_data = tf.data.TFRecordDataset(tf_files,
                                          compression_type=None,
                                          buffer_size=self.fileBufferSize,
                                          num_parallel_reads=self.fileParallelReads
                                          )
        tf_data = tf_data.map(self.tfRecordConvertor.bytesToTensor)
        tf_data = tf_data.shuffle(self.dataBufferSize)
        tf_data = tf_data.repeat(self.dataRepeat)

        if self.batchSize:
            tf_data = tf_data.batch(self.batchSize, drop_remainder=True)

        tf_data = tf_data.map(self._data_mapper)
        tf_iterator = tf_data.make_initializable_iterator()
        return tf_iterator

    def recordIterator(self, output_types, output_shapes):
        handle = tf.placeholder(tf.string, shape=[])
        iterator = tf.data.Iterator.from_string_handle(
            handle, output_types, output_shapes)
        next_record = iterator.get_next()

        return next_record


if __name__ == '__main__':
    featureNames = ["vid", "labels"]
    featureTypes = [tf.int64, tf.int64]
    featureDims = [1, 0]
    tc = TFRecordConvertor(featureNames, featureTypes, featureDims)

    trainReader = TFRecordReader(tc, '../data/*.tf')
    testReader = TFRecordReader(tc, '../data/*.tf')

    train_iterator = trainReader.read()
    test_iterator = testReader.read()

    handle = tf.placeholder(tf.string, shape=[])
#     iterator = tf.data.Iterator.from_string_handle(
#         handle, output_types, output_shapes)
    iterator = tf.data.Iterator.from_string_handle(
        handle, train_iterator.output_types)
    next_record = iterator.get_next()

    print(train_iterator.output_types)
    print(train_iterator.output_shapes)

    init = (tf.global_variables_initializer(),
            tf.local_variables_initializer())
    with tf.Session() as sess:
        sess.run(init)
        sess.run(train_iterator.initializer)
        sess.run(test_iterator.initializer)
        train_handle = sess.run(train_iterator.string_handle())
        test_handle = sess.run(test_iterator.string_handle())

        while True:
            try:
                b = sess.run(next_record, feed_dict={handle: train_handle})
                print(b)
            except tf.errors.OutOfRangeError:
                break

        while True:
            try:
                b = sess.run(next_record, feed_dict={handle: test_handle})
                print(b)
            except tf.errors.OutOfRangeError:
                break
